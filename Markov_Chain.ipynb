{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install markovify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMeOH0j40mGi",
        "outputId": "db00ea66-b87b-4c6f-f83d-4e2459086825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode (from markovify)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18608 sha256=1d8f07ff2b312e3a69ac900f1b8eb0c82449003bb86e9bfda27fce077cd2800c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/8c/c5/41413e24c484f883a100c63ca7b3b0362b7c6f6eb6d7c9cc7f\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import markovify #ready-to-use text Markov chain"
      ],
      "metadata": {
        "id": "gQlKka2u0lTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V1ZEAoNz_pe",
        "outputId": "7321bcc0-8d95-46c7-a048-e3b455accf63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpHE3cEm0Pn7",
        "outputId": "8467a5c3-aad9-4451-e062-e9dcde5f615c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'libfluidsynth1' has no installation candidate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB04iTsK0WtU",
        "outputId": "05eb5068-60eb-4eaa-df9b-fac6b9de17af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy) (2024.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
            "Installing collected packages: cartopy\n",
            "Successfully installed cartopy-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"/content/arxivData.json\")\n",
        "print(df.head())  # Print the first few rows to verify the data loaded correctly"
      ],
      "metadata": {
        "id": "loODXu8Z09rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7f1c22-0d6e-4bec-a45e-e40332e1cfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              author  day            id  \\\n",
            "0  [{'name': 'Ahmed Osman'}, {'name': 'Wojciech S...    1  1802.00209v1   \n",
            "1  [{'name': 'Ji Young Lee'}, {'name': 'Franck De...   12  1603.03827v1   \n",
            "2  [{'name': 'Iulian Vlad Serban'}, {'name': 'Tim...    2  1606.00776v2   \n",
            "3  [{'name': 'Sebastian Ruder'}, {'name': 'Joachi...   23  1705.08142v2   \n",
            "4  [{'name': 'Iulian V. Serban'}, {'name': 'Chinn...    7  1709.02349v2   \n",
            "\n",
            "                                                link  month  \\\n",
            "0  [{'rel': 'alternate', 'href': 'http://arxiv.or...      2   \n",
            "1  [{'rel': 'alternate', 'href': 'http://arxiv.or...      3   \n",
            "2  [{'rel': 'alternate', 'href': 'http://arxiv.or...      6   \n",
            "3  [{'rel': 'alternate', 'href': 'http://arxiv.or...      5   \n",
            "4  [{'rel': 'alternate', 'href': 'http://arxiv.or...      9   \n",
            "\n",
            "                                             summary  \\\n",
            "0  We propose an architecture for VQA which utili...   \n",
            "1  Recent approaches based on artificial neural n...   \n",
            "2  We introduce the multiresolution recurrent neu...   \n",
            "3  Multi-task learning is motivated by the observ...   \n",
            "4  We present MILABOT: a deep reinforcement learn...   \n",
            "\n",
            "                                                 tag  \\\n",
            "0  [{'term': 'cs.AI', 'scheme': 'http://arxiv.org...   \n",
            "1  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
            "2  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
            "3  [{'term': 'stat.ML', 'scheme': 'http://arxiv.o...   \n",
            "4  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
            "\n",
            "                                               title  year  \n",
            "0  Dual Recurrent Attention Units for Visual Ques...  2018  \n",
            "1  Sequential Short-Text Classification with Recu...  2016  \n",
            "2  Multiresolution Recurrent Neural Networks: An ...  2016  \n",
            "3  Learning what to share between loosely related...  2017  \n",
            "4              A Deep Reinforcement Learning Chatbot  2017  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[\"title\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2lNm-iXqsKc",
        "outputId": "85a9ba60-d6a1-403e-adce-eb3bf6606863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41000"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"title\"][0])\n",
        "print(\"\\n\")\n",
        "print(df[\"summary\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtTfbxAxrAtq",
        "outputId": "08324e46-a43b-45e4-9755-a8ceb37e1f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dual Recurrent Attention Units for Visual Question Answering\n",
            "\n",
            "\n",
            "We propose an architecture for VQA which utilizes recurrent layers to\n",
            "generate visual and textual attention. The memory characteristic of the\n",
            "proposed recurrent attention units offers a rich joint embedding of visual and\n",
            "textual features and enables the model to reason relations between several\n",
            "parts of the image and question. Our single model outperforms the first place\n",
            "winner on the VQA 1.0 dataset, performs within margin to the current\n",
            "state-of-the-art ensemble model. We also experiment with replacing attention\n",
            "mechanisms in other state-of-the-art models with our implementation and show\n",
            "increased accuracy. In both cases, our recurrent attention mechanism improves\n",
            "performance in tasks requiring sequential or relational reasoning on the VQA\n",
            "dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenating titles and abstract in new column\n",
        "df[\"all_text\"] = df[\"title\"] + \": \" + df[\"summary\"]\n",
        "df[\"all_text\"] = df[\"all_text\"].map(lambda x : x.replace(\"\\n\", \" \"))\n",
        "#df.head(5)\n",
        "df[\"all_text\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "yzAWAlcR4tdb",
        "outputId": "6d60ff28-74c2-4326-f732-771b90d0c44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dual Recurrent Attention Units for Visual Question Answering: We propose an architecture for VQA which utilizes recurrent layers to generate visual and textual attention. The memory characteristic of the proposed recurrent attention units offers a rich joint embedding of visual and textual features and enables the model to reason relations between several parts of the image and question. Our single model outperforms the first place winner on the VQA 1.0 dataset, performs within margin to the current state-of-the-art ensemble model. We also experiment with replacing attention mechanisms in other state-of-the-art models with our implementation and show increased accuracy. In both cases, our recurrent attention mechanism improves performance in tasks requiring sequential or relational reasoning on the VQA dataset.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of words defining a state in the text Markov chain\n",
        "STATE_SIZE = 3\n",
        "\n",
        "#generating a model for all the text and one only for titles\n",
        "text_model = markovify.Text( df[\"all_text\"], state_size=STATE_SIZE)\n",
        "title_model = markovify.Text( df[\"title\"], state_size=STATE_SIZE)"
      ],
      "metadata": {
        "id": "54ou3i5A4wkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findnth( str, char=\" \", n=2):\n",
        "    \"\"\"\n",
        "    Returns position of n-th occurence of pattern in a string\n",
        "    \"\"\"\n",
        "\n",
        "    index_from_beg = 0\n",
        "    while n >= 1:\n",
        "        index = str.find( char)\n",
        "        str = str[index+1:]\n",
        "        index_from_beg += index + len(char)\n",
        "        n -= 1\n",
        "    return index_from_beg\n",
        "\n",
        "sample_size = 7\n",
        "successes = 0\n",
        "while successes < sample_size:\n",
        "    try: #some make_sentence calls raise a KeyError exception for misunderstood reasons\n",
        "        #first generating a title\n",
        "        _title = title_model.make_sentence()\n",
        "        _end_of_title = \" \".join( _title.split()[-STATE_SIZE:])\n",
        "\n",
        "        #generating abstract from the end of the tile\n",
        "        _abstract = text_model.make_sentence_with_start( _end_of_title)\n",
        "\n",
        "        #concatenating both\n",
        "        index = findnth( _abstract, \" \", 2)\n",
        "        _abstract = _abstract[index:]\n",
        "        _full_article_description = _title + \" \" + _abstract\n",
        "        print( _full_article_description, end=\"\\n\\n\")\n",
        "        successes += 1\n",
        "\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vktNaAK41MR",
        "outputId": "34643af3-8595-48f3-96a4-4111bdc16e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Construction of neural networks for object detection and instance segmentation segmentation of people in a sequence and another LSTM model is trained using supervised learning techniques.\n",
            "\n",
            "Efficient Privacy Preserving Viola-Jones Type Object Detection via Fully Convolutional Networks Networks are trained and tested a first version of Morphonette, a new French morphological resource and a new dataset and the route planning application.\n",
            "\n",
            "ChainerCV: a Library for Deep Neural Networks Networks and their Applications: The Artificial Neural network is used or a new set of N items that will be more precise than that in {Klopotek:93f} approach exists and on the Good-Turing missing mass estimator.\n",
            "\n",
            "Learning Parameters for Weighted Matrix Completion via Non-convex Stochastic Gradient Descent Descent algorithm is widely used as building blocks for probabilistic computation.\n",
            "\n",
            "Prosodic Features from Large Weakly Supervised Data for Dialogue Management Management Based on Scripts and Meta-Outputs: We describe an architecture for large-scale deep learning networks is also explored.\n",
            "\n",
            "Dropout Inference in Bayesian Networks Networks and Genetic Algorithm: A method based on peak registration called BARCHAN.\n",
            "\n",
            "A Robust Alternating Direction Method of Multipliers Multipliers for a Class of Single-Product Revenue Management Problems: We consider convex-concave saddle point problem.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHqUxRFu5EyT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}